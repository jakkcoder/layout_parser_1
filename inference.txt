import os
import sys
os.path.join(os.getcwd(),"detectron2/detectron2")
sys.path.append(os.path.join(os.getcwd(),"pytorch-image-models"))
import cv2
import torch
import shutil
import gradio as gr
import numpy as np
from fastapi import FastAPI, File, UploadFile
import pypdfium2 as pdfium
from pydantic import BaseModel
from detectron2.config import get_cfg
from detectron2.config import CfgNode as CN
from detectron2.data import MetadataCatalog
from detectron2.engine import DefaultPredictor
from unilm.dit.object_detection.ditod import add_vit_config
from detectron2.utils.visualizer import ColorMode, Visualizer
import warnings
warnings.filterwarnings('ignore')

# Step 1: instantiate config
cfg = get_cfg()
add_vit_config(cfg)
cfg.merge_from_file("cascade_dit_base.yml")

# Step 2: add model weights URL to config
# cfg.MODEL.WEIGHTS = "publaynet_dit-b_cascade.pth"
cfg.MODEL.WEIGHTS = "publaynet_dit-b_cascade.pth"
# Step 3: set device
cfg.MODEL.DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST= .2
cfg.MODEL.ROI_HEADS.NMS_THRESH_TEST = .6
# Step 4: define model
predictor = DefaultPredictor(cfg)


def analyze_image(img):
    md = MetadataCatalog.get(cfg.DATASETS.TEST[0])
    if cfg.DATASETS.TEST[0]=='icdar2019_test':
        md.set(thing_classes=["table"])
    else:
        md.set(thing_classes=["text","title","list","table","figure"])
    
    output = predictor(img)["instances"]
    v = Visualizer(img[:, :, ::-1],
                    md,
                    scale=1.0,
                    instance_mode=ColorMode.SEGMENTATION)
    result = v.draw_instance_predictions(output.to("cpu"))
    result_image = result.get_image()[:, :, ::-1]
    
    return result_image



app = FastAPI()

# Define the input schema using Pydantic
class InputData(BaseModel):
    text: str

@app.post("/predict/")
async def p(pdf: UploadFile):
    """    Parse a PDF file to extract layout details.

    This endpoint takes a PDF file as input and uses a layout parser to extract layout information, including strings, figures, titles, bounding box coordinates, class probabilities, and class names. The layout parser processes the PDF file and provides structured output.

    Args:
        pdf_file (UploadFile): The PDF file to be processed.

    Returns:
        List[LayoutDetail]: A list of layout details for the PDF, including:
            - text (str): Extracted text content.
            - figure (bool): True if the element is a figure, False otherwise.
            - title (bool): True if the element is a title, False otherwise.
            - bounding_box (List[int]): Bounding box coordinates [left, top, right, bottom].
            - class_probability (float): Probability score for the class.
            - class_name (str): Name of the class.
    """

    
    # Directory to store uploaded PDFs
    upload_directory = "uploaded_pdfs"
    
    # Create the upload directory if it doesn't exist
    os.makedirs(upload_directory, exist_ok=True)
    file_path = os.path.join(upload_directory, pdf.filename)
    #####
    if not os.path.exists(file_path):
        with open(file_path, "wb") as pdf_file:
            shutil.copyfileobj(pdf.file, pdf_file)
    
    try:
        pdf = pdfium.PdfDocument(file_path)
        n_pages =  len(pdf)
        all_results = {}
        for page_number in range(n_pages):
            page = pdf.get_page(page_number)
            pil_image = page.render(scale=300/72).to_pil()
            img = np.array(pil_image)
            output = predictor(img)["instances"]
            del output.get_fields()['pred_masks']
            all_results[page_number]= output.get_fields()
        return all_results
    except Exception as e:
        return ("error", str(e))


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app,host ="0.0.0.0",port= 8008)
