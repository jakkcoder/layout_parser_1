from pyspark.sql import SparkSession

# Initialize a Spark session
spark = SparkSession.builder \
    .appName('Spark BigQuery Example') \
    .config('spark.jars.packages', 'com.google.cloud.spark:spark-bigquery-with-dependencies_2.12:0.27.0') \
    .getOrCreate()

# Set GCP credentials
spark.conf.set("parentProject", "your_project_id")
spark.conf.set("credentialsFile", "/path/to/your/credentials.json")

# Read from BigQuery
df = spark.read.format('bigquery') \
    .option('project', 'your_project_id') \
    .option('dataset', 'your_dataset_id') \
    .option('table', 'your_table_id') \
    .load()

# Show the DataFrame
df.show()
