
from google.cloud import bigquery
import json

# Initialize a BigQuery client
client = bigquery.Client()

# Your BigQuery table information
dataset_id = 'built_with_testing'
table_id = 'bw_data_test'

# Function to parse fields recursively
def parse_schema_fields(fields):
    schema = []
    for field in fields:
        if field['type'] == 'RECORD':
            schema.append(
                bigquery.SchemaField(
                    name=field['name'],
                    field_type=field['type'],
                    mode=field['mode'],
                    fields=parse_schema_fields(field['fields'])
                )
            )
        else:
            schema.append(
                bigquery.SchemaField(
                    name=field['name'],
                    field_type=field['type'],
                    mode=field['mode']
                )
            )
    return schema

# Load the schema from the JSON file
with open('nested_schema.json', 'r') as schema_file:
    schema_json = json.load(schema_file)

# Parse the schema
schema = parse_schema_fields(schema_json)

# Your data in dictionary format
data = [
    {"name": "John Doe", "age": 30, "address": {"city": "New York", "state": "NY"}},
    {"name": "Jane Smith", "age": 25, "address": {"city": "Los Angeles", "state": "CA"}},
    # Add more records as necessary
]

# Reference to your table
table_ref = client.dataset(dataset_id).table(table_id)

# Load data into BigQuery table
errors = client.insert_rows_json(table_ref, data)  # Make an API request to insert data

if errors:
    print("Errors occurred while inserting rows: {}".format(errors))
else:
    print("Data successfully appended to the table.")
